# Practical Examples: R Vignette for Polling API

---
title: "Working with the Zweitstimme Polling API"
author: "Your Name"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Working with the Zweitstimme Polling API}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  warning = FALSE,
  message = FALSE
)
```

## Introduction

This vignette demonstrates how to use the Zweitstimme Polling API for political science research. We'll work with German federal election polling data using the `httr2` package and standard tidyverse tools.

## Setup

First, load the required packages:

```{r load-packages}
library(httr2)      # For API requests
library(dplyr)      # For data manipulation
library(purrr)      # For functional programming
library(ggplot2)    # For visualization
library(lubridate)  # For date handling
library(tidyr)      # For data reshaping
library(zoo)        # For time series operations
```

## Understanding the API Structure

The API provides several types of data:

- **Polls**: Individual polling results with metadata
- **Results**: Flattened party results for analysis
- **Reference tables**: Information about institutes, parties, methods, and elections

All API responses are in JSON format with a consistent structure including `items` (the data) and `meta` (pagination info).

## Example 1: Basic Data Retrieval

Let's start by fetching the most recent federal polls:

```{r basic-request}
# Request recent federal polls
response <- request("https://api.fasttrack29.com/v1/polls") |>
  req_url_query(
    scope = "federal",
    limit = 10
  ) |>
  req_perform()

# Check the response
resp_status(response)

# Parse the JSON
polls_data <- resp_body_json(response)

# Examine structure
str(polls_data, max.level = 2)
```

The response contains `items` (the polls) and `meta` (pagination information).

## Example 2: Converting to Tidy Data

API data is nested JSON. Let's convert it to a tidy data frame:

```{r tidy-data}
# Extract poll metadata
polls_summary <- map_dfr(polls_data$items, function(poll) {
  tibble(
    id = poll$id,
    publish_date = as.Date(poll$publish_date),
    institute = poll$institute_name,
    respondents = as.integer(poll$respondents),
    scope = poll$scope
  )
})

head(polls_summary)

# Extract party results
poll_results <- map_dfr(polls_data$items, function(poll) {
  map_dfr(poll$results, function(result) {
    tibble(
      poll_id = poll$id,
      publish_date = as.Date(poll$publish_date),
      institute = poll$institute_name,
      party = result$party_short_name,
      percentage = result$percentage
    )
  })
})

head(poll_results)
```

## Example 3: Time Series Analysis

Let's analyze party support trends over the past year:

```{r time-series}
# Get all federal polls from 2024
all_polls <- request("https://api.fasttrack29.com/v1/polls") |>
  req_url_query(
    scope = "federal",
    date_from = "2024-01-01",
    limit = 200
  ) |>
  req_perform() |>
  resp_body_json()

# Convert to tidy format
tidy_data <- map_dfr(all_polls$items, function(poll) {
  map_dfr(poll$results, function(result) {
    tibble(
      date = as.Date(poll$publish_date),
      institute = poll$institute_name,
      party = result$party_short_name,
      percentage = result$percentage
    )
  })
})

# Calculate rolling averages
rolling_data <- tidy_data |>
  group_by(party) |>
  arrange(date) |>
  mutate(
    rolling_avg = rollmean(percentage, k = 7, fill = NA, align = "right")
  ) |>
  ungroup()

# Plot trends
ggplot(rolling_data, aes(x = date, color = party)) +
  geom_point(aes(y = percentage), alpha = 0.2, size = 0.8) +
  geom_line(aes(y = rolling_avg), size = 1) +
  labs(
    title = "German Federal Polling Trends in 2024",
    subtitle = "Individual polls (transparent) and 7-poll rolling average",
    x = "Date",
    y = "Support (%)",
    color = "Party"
  ) +
  theme_minimal() +
  scale_y_continuous(limits = c(0, NA))
```

## Example 4: Comparing Polling Institutes

Different institutes may show systematic differences. Let's compare them:

```{r compare-institutes}
# Get reference data for parties (for colors)
parties_ref <- request("https://api.fasttrack29.com/v1/reference/parties") |>
  req_perform() |>
  resp_body_json() |>
  bind_rows()

party_colors <- parties_ref |>
  select(short_name, color) |>
  filter(!is.na(color)) |>
  deframe()

# Focus on major parties
major_parties <- c("CDU/CSU", "SPD", "GrÃ¼ne", "AfD")

# Calculate institute averages
institute_comparison <- tidy_data |>
  filter(party %in% major_parties) |>
  group_by(institute, party) |>
  summarise(
    avg_support = mean(percentage),
    n_polls = n(),
    .groups = 'drop'
  ) |>
  filter(n_polls >= 5)  # Only institutes with sufficient data

# Plot comparison
ggplot(institute_comparison, aes(x = reorder(institute, avg_support), 
                                  y = avg_support, 
                                  fill = party)) +
  geom_col(position = "dodge") +
  coord_flip() +
  scale_fill_manual(values = party_colors) +
  labs(
    title = "Average Party Support by Polling Institute (2024)",
    subtitle = "Only institutes with 5+ polls shown",
    x = "Institute",
    y = "Average Support (%)",
    fill = "Party"
  ) +
  theme_minimal()
```

## Example 5: Polling Volatility

How much do polls vary? Let's measure volatility:

```{r volatility}
# Calculate volatility metrics
volatility <- tidy_data |>
  filter(party %in% major_parties) |>
  group_by(party) |>
  summarise(
    mean_support = mean(percentage),
    sd_support = sd(percentage),
    min_support = min(percentage),
    max_support = max(percentage),
    range = max_support - min_support,
    n_polls = n(),
    .groups = 'drop'
  ) |>
  arrange(desc(sd_support))

print(volatility)

# Visualize volatility
ggplot(tidy_data |> filter(party %in% major_parties), 
       aes(x = party, y = percentage, fill = party)) +
  geom_boxplot(alpha = 0.7) +
  geom_jitter(alpha = 0.2, width = 0.2) +
  scale_fill_manual(values = party_colors) +
  labs(
    title = "Polling Volatility by Party (2024)",
    y = "Support (%)",
    x = "Party"
  ) +
  theme_minimal() +
  theme(legend.position = "none")
```

## Example 6: Election Proximity Effect

Do polls become more accurate or stable as elections approach?

```{r election-proximity}
# Get election information
elections <- request("https://api.fasttrack29.com/v1/reference/elections") |>
  req_perform() |>
  resp_body_json() |>
  bind_rows()

# Find next federal election
next_election <- elections |>
  filter(election_type == "Bundestagswahl", 
         as.Date(date) > Sys.Date()) |>
  arrange(date) |>
  slice(1)

if (nrow(next_election) > 0) {
  election_date <- as.Date(next_election$date)
  
  # Calculate days to election
  proximity_data <- tidy_data |>
    mutate(
      days_to_election = as.numeric(election_date - date),
      weeks_to_election = floor(days_to_election / 7)
    ) |>
    filter(days_to_election >= 0, days_to_election <= 365) |>
    filter(party %in% major_parties)
  
  # Plot proximity effect
  ggplot(proximity_data, aes(x = days_to_election, y = percentage, color = party)) +
    geom_point(alpha = 0.3) +
    geom_smooth(method = "loess", se = TRUE) +
    scale_x_reverse() +
    scale_color_manual(values = party_colors) +
    labs(
      title = "Polling Trends as Election Approaches",
      subtitle = paste("Election date:", format(election_date, "%d.%m.%Y")),
      x = "Days to Election",
      y = "Support (%)",
      color = "Party"
    ) +
    theme_minimal()
} else {
  message("No upcoming federal election found in data")
}
```

## Example 7: Method Effects

Do different polling methods produce different results?

```{r method-effects}
# Get polls with method information
polls_with_method <- request("https://api.fasttrack29.com/v1/polls") |>
  req_url_query(
    scope = "federal",
    date_from = "2024-01-01",
    limit = 200
  ) |>
  req_perform() |>
  resp_body_json()

# Extract method info
data_by_method <- map_dfr(polls_with_method$items, function(poll) {
  if (!is.null(poll$results)) {
    map_dfr(poll$results, function(result) {
      if (result$party_short_name %in% major_parties) {
        tibble(
          method = poll$method_name %||% "Unknown",
          party = result$party_short_name,
          percentage = result$percentage
        )
      }
    })
  }
})

# Calculate averages by method
method_comparison <- data_by_method |>
  filter(!is.na(method)) |>
  group_by(method, party) |>
  summarise(
    avg = mean(percentage),
    n = n(),
    .groups = 'drop'
  ) |>
  filter(n >= 10)  # Sufficient sample size

# Visualize
ggplot(method_comparison, aes(x = method, y = avg, fill = party)) +
  geom_col(position = "dodge") +
  facet_wrap(~party) +
  scale_fill_manual(values = party_colors) +
  labs(
    title = "Average Support by Polling Method",
    subtitle = "Only methods with 10+ polls",
    x = "Method",
    y = "Average Support (%)"
  ) +
  theme_minimal() +
  theme(legend.position = "none", axis.text.x = element_text(angle = 45, hjust = 1))
```

## Example 8: Creating Reusable Functions

Build functions for common tasks:

```{r helper-functions}
# Function to fetch polls with automatic pagination
fetch_all_polls <- function(scope = "federal", date_from = NULL, date_to = NULL) {
  all_items <- list()
  offset <- 0
  limit <- 500
  
  repeat {
    req <- request("https://api.fasttrack29.com/v1/polls") |>
      req_url_query(
        scope = scope,
        limit = limit,
        offset = offset
      )
    
    if (!is.null(date_from)) {
      req <- req |> req_url_query(date_from = date_from)
    }
    if (!is.null(date_to)) {
      req <- req |> req_url_query(date_to = date_to)
    }
    
    response <- req |>
      req_perform() |>
      resp_body_json()
    
    all_items <- c(all_items, response$items)
    
    if (length(response$items) < limit) break
    offset <- offset + limit
    Sys.sleep(0.1)  # Be nice to the API
  }
  
  message("Retrieved ", length(all_items), " polls")
  return(all_items)
}

# Function to convert to tidy format
tidy_polls <- function(polls_list) {
  map_dfr(polls_list, function(poll) {
    if (!is.null(poll$results)) {
      map_dfr(poll$results, function(result) {
        tibble(
          date = as.Date(poll$publish_date),
          institute = poll$institute_name,
          method = poll$method_name,
          respondents = as.integer(poll$respondents),
          party_id = result$party_id,
          party = result$party_short_name,
          percentage = result$percentage
        )
      })
    }
  })
}

# Use the functions
polls_2024 <- fetch_all_polls(scope = "federal", date_from = "2024-01-01")
tidy_2024 <- tidy_polls(polls_2024)

head(tidy_2024)
```

## Example 9: Exporting Data

Save your analysis for use in other tools:

```{r export}
# Save as CSV for Excel/SPSS
write.csv(tidy_2024, "polling_data_2024.csv", row.names = FALSE)

# Save as RDS for R
saveRDS(tidy_2024, "polling_data_2024.rds")

# Save summary statistics
summary_table <- tidy_2024 |>
  group_by(party) |>
  summarise(
    n = n(),
    mean = mean(percentage),
    sd = sd(percentage),
    .groups = 'drop'
  )

write.csv(summary_table, "polling_summary_2024.csv", row.names = FALSE)
```

## Summary

This vignette demonstrated:

1. **Basic API requests** using `httr2`
2. **Data transformation** from JSON to tidy format
3. **Time series analysis** with rolling averages
4. **Comparative analysis** across institutes and methods
5. **Volatility measurement** and visualization
6. **Reusable functions** for common tasks
7. **Data export** for further analysis

## Further Resources

- Full API documentation: https://api.fasttrack29.com
- API reference: See the documentation site
- Data & Pipeline: Understanding data sources and processing
- httr2 package: https://httr2.r-lib.org/

## Session Information

```{r session-info}
sessionInfo()
```
